{
    "collab_server" : "",
    "contents" : "---\ntitle: \"Week4\"\nauthor: \"Sumit Kant\"\ndate: \"14 May 2017\"\noutput: html_document\n---\n\n# Regularized Regression\n\n```{r}\nlibrary(ElemStatLearn)\ndata(\"prostate\")\nstr(prostate)\n```\n\nSometimes you may re-perform the splitting and analysis several times. In order to get a better average estimate of what the out of sample error rate will be. Two common problems\n1. Lmimted data\n2. Computational Complexity\n\nSo another approach is to try to decompose the prediction error. \nSo if we assume that the variable y can be predicted as a function of x, plus some error term, then expected prediction error is the expected difference between the outcome and the prediction of the \n\nExpected mean square error is a composition of\n1. Irreducible Erro\n2. Bias sqaured\n3. Variance\n\nThe goal is to reduce the sum of all the above.\n\n## Large predictors small data \n\nSubsampling will produce estimates for some variables and return NA for others since the data is small and predictors are large\nTo counter this we can go for hard thresholding.\n\n## Hard Thresholding\n\n# COMBINING PREDICTORS\n\n## Model Stacking\n```{r}\nlibrary(ISLR)\ndata(Wage)\nlibrary(ggplot2)\nlibrary(caret)\n\nWage <- subset(Wage, select = c(-logwage))\n\n# Building dataset and validation set\ninBuild <- createDataPartition(y = Wage$wage, p = 0.7, list = F)\nvalidation <- Wage[-inBuild,]\nbuildData <- Wage[inBuild,]\ninTrain <- createDataPartition(y = buildData$wage, p=0.7, list = F)\ntraining <- buildData[inTrain, ]\ntesting <- buildData[-inTrain, ]\n```\n\n```{r}\ndim(training)\n```\n\n```{r}\ndim(testing)\n```\n\n```{r}\ndim(validation)\n```\n\n## Building two different models\n\n```{r warning = FALSE}\nmod1 <- train(wage ~., method = \"glm\", data = training)\nmod2 <- train(wage ~., method = \"rf\", \n              data = training, \n              trControl = trainControl(method = \"cv\"), number = 3)\n```\n\n## Prediction on testing set\n\n```{r}\npred1 <- predict(mod1, testing)\n\npred2 <- predict(mod2, testing)\n\nqplot(pred1, pred2, color = wage, data = testing)\n```\n\n## Fitting the model that combines the predictors\n\nBuild a new data set from predictions of both model 1 and 2\nRelation outcome of the predictions from the two models.\n\n```{r message=FALSE}\npredDF <- data.frame(pred1, pred2, wage  = testing$wage)\ncombModFit <- train(wage ~ ., method = \"gam\", data = predDF)\ncombPred <- predict(combModFit, predDF)\n```\n\n```{r}\nqplot(combPred, pred2, color = predDF$wage)\n```\n\n```{r}\nqplot(combPred, pred1, color = predDF$wage)\n```\n\n\n## Testing Errors\n\nError in first predictor\n\n```{r}\nsqrt(sum((pred1 - testing$wage)^2))\n```\n\nError in second predictor\n\n```{r}\nsqrt(sum((pred2 - testing$wage)^2))\n```\n\nError in combine predictor\n```{r}\nsqrt(sum((combPred - testing$wage)^2))\n```\n\nwhich is lower than both predictor 1 and 2\n\n## Predict on the validation set\n\n```{r warning=FALSE}\npred1V <- predict(mod1, validation)\npred2V <- predict(mod2, validation)\npredVDF <- data.frame(pred1 = pred1V, pred2 = pred2V)\ncombPredV <- predict(combModFit, predVDF)\n```\n\n## Evaluation on the validation set\n\nError in first predictor\n\n```{r}\nsqrt(sum((pred1V - validation$wage)^2))\n```\n\nError in second predictor\n\n```{r}\nsqrt(sum((pred2V - validation$wage)^2))\n```\n\nError in combine predictor\n```{r}\nsqrt(sum((combPredV - validation$wage)^2))\n```\n\nStacking models in this way can reduce errors and improve accuracy.\n\n\n# FORECASTING\n\n## Forecasting Google data\n\n```{r warning=FALSE}\n# install.packages(\"quantmod\")\nlibrary(quantmod)\nfrom.dat <- as.Date(\"01/01/10\", format = \"%m/%d/%y\")\nto.dat <- as.Date(\"12/31/14\", format = \"%m/%d/%y\")\ngetSymbols(\"MSFT\", src =\"google\", from = from.dat, to = to.dat)\ngetSymbols(\"AAPL\", src =\"google\", from = from.dat, to = Sys.Date())\n```\n\n```{r}\nhead(MSFT)\n```\n\n## Summarize monthly and store as time series\n\n```{r}\nmMsft <- to.monthly(MSFT)\nmsftOpen <- Op(mMsft)\nts1 <- ts(msftOpen, frequency = 12)\nplot(ts1, xlab =\"Years + 1\", ylab = \"MSFT\")\n```\n\n## Example time series decomposition\n\n* TREND\n* SEASONAL\n* CYCLIC\n\n```{r}\nplot(decompose(ts1), xlab =\"Years + 1\")\n```\n\n## Training and test sets\n\n```{r}\nts1train <- window(ts1, start = 1, end = 5)\nts1test <- window(ts1, start = 5, end = (6 - 0.01))\nts1train\n```\n\n## Ways to do forecasting\n\n### SIMPLE MOVING AVERAGE\n\n```{r}\nlibrary(forecast)\nplot(ts1train)\nlines(ma(ts1train, order = 3), col =\"red\")\n```\n\n### EXPONENTIAL SMOOTHING\n\n```{r}\nets1 <- ets(ts1train, model = \"MMM\")\nfcast <- forecast(ets1)\nplot(fcast)\nlines(ts1test, col =\"red\")\n```\n\n## Getting accuracy\n\n```{r}\naccuracy(fcast, ts1test)\n```\n\n\n# UNSUPERVISED PREDICTION \n\n## Load IRIS data\n```{r}\ndata(\"iris\")\nlibrary(ggplot2)\n\ninTrain <- createDataPartition(y = iris$Species, p =0.7, list = F)\ntraining <- iris[inTrain,]\ntesting <- iris[-inTrain,]\ndim(training)\n```\n\n```{r}\ndim(testing)\n```\n\n\n## K-Means clustering\n```{r}\nkmeans1 <- kmeans(subset(training, select = -c(Species)), centers = 3)\ntraining$clusters <- as.factor(kmeans1$cluster)\nqplot(Petal.Width, Petal.Length, color = clusters, data = training)\n```\n\n## Compare to real labels\n\n```{r}\ntable(kmeans1$cluster, training$Species)\n```\n\n\n## Build predictor\n\n```{r}\nmodFit <- train(clusters ~ ., data = subset(training, select =-c(Species)),\n                method = \"rpart\")\ntable(predict(modFit, training), training$Species)\n```\n\n## Apply on test dataset\n\n```{r}\ntestCLusterPred <- predict(modFit, testing)\ntable(testCLusterPred, testing$Species)\n```\n\n",
    "created" : 1494939515700.000,
    "dirty" : true,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "387754856",
    "id" : "40DA07FA",
    "lastKnownWriteTime" : 1494748556,
    "last_content_update" : 1494939857067,
    "path" : "D:/Data Analyst/R/Coursera - Practical Machine Learning/Week 4/Week4.Rmd",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_markdown"
}